---
import BaseLayout from '../../layouts/BaseLayout.astro';
import CnnVsVitDiagram from '../../components/CnnVsVitDiagram.astro';
import ViTArchitecture from '../../components/ViTArchitecture.astro';
import VLMArchitecture from '../../components/VLMArchitecture.astro';
import { yesterdayYmd } from '../../utils/date';

const createdAt = yesterdayYmd();
---

<BaseLayout title="深入理解 Vision Transformer (ViT)">
    <header class="text-center mb-12">
        <h1 class="text-4xl font-bold mb-4 gradient-text">为什么 AI 能看懂图片？</h1>
        <p class="text-xl text-gray-500">深入解析 Vision Transformer (ViT) 及其在现代 VLM 中的核心地位</p>
        <p class="mt-4 text-sm uppercase tracking-[0.2em] text-[color:var(--muted)]">添加时间 {createdAt}</p>
    </header>

    <div class="card">
        <h2>前言：从文本到视觉的跨越</h2>
        <p>你有没有想过，为什么现在的 AI 不仅能聊天，还能分析你的照片、截图甚至视频？答案就在今天的主角 —— <span class="highlight">ViT (Vision Transformer)</span> 身上。</p>
        <p>没有 ViT，AI 模型可能根本没法像今天这样高效地"看"图。ViT 究竟是为了解决什么问题提出的？它的核心方法是什么？它又是如何打破了 CNN（卷积神经网络）长久以来的统治？</p>
        <div class="bg-blue-50 p-4 rounded-lg border border-blue-100">
            <strong>核心定义：</strong> ViT (Vision Transformer) 是一个基于 Transformer 架构的深度学习模型，专门用来处理和理解图像数据。其核心思想源自 2020 年 Google 团队的论文 <em>"An Image is Worth 16x16 Words"</em>。
        </div>
    </div>

    <div class="card">
        <h2>1. 为什么要用 Transformer？(CNN 的局限性)</h2>
        <p>在 ViT 出现之前，图像处理的霸主是 CNN。CNN 虽然强大，但被一种叫做<strong>归纳偏置 (Inductive Bias)</strong> 的东西"锁"住了。</p>

        <h3 class="text-blue-600">CNN 的困境：拿着放大镜看地图</h3>
        <ul class="list-disc pl-6 mb-4 space-y-2 text-gray-600">
            <li><strong>感受野受限：</strong> CNN 依赖卷积核（如 3x3），一次只能看一小块区域。要理解全图，必须堆叠极深的网络。</li>
            <li><strong>缺乏全局建模：</strong> 很难一步到位捕捉左下角和右上角像素的关系。</li>
            <li><strong>扩展性瓶颈：</strong> 增加层数并不总是能带来性能提升，大模型优化困难。</li>
        </ul>

        <CnnVsVitDiagram />

        <p>Transformer 通过<strong>自注意力机制 (Self-Attention)</strong>，天生就能建模全局依赖关系。无论图片多大，左上角的像素都能直接"关注"到右下角的像素。</p>
    </div>

    <div class="card">
        <h2>2. ViT 核心原理：把图片切成"文字"</h2>
        <p>ViT 的核心思想简单而暴力：既然 Transformer 处理的是序列（像句子一样的单词流），那我们就把图片变成序列。</p>

        <h3 class="text-blue-600">Step 1: Image Patching (切豆腐)</h3>
        <p>
            将一张 <span set:html={"$H \\times W$"}></span> 的图片，切成 <span set:html={"$N$"}></span> 个大小为 <span set:html={"$P \\times P$"}></span> 的小方块（Patch）。例如，一张 224x224 的图，如果 Patch 大小是 16x16，就会被切成 <span set:html={"$14 \\times 14 = 196$"}></span> 个 Patch。
        </p>

        <h3 class="text-blue-600">Step 2: Linear Projection (压扁成向量)</h3>
        <p>
            每个 Patch 本质上是一个 <span set:html={"$16 \\times 16 \\times 3$"}></span> 的像素块。ViT 会把它展平，然后通过一个可学习的线性层，投射到一个固定维度 <span set:html={"$D$"}></span> 的向量空间中。这就是 <strong>Patch Embedding</strong>。
        </p>

        <h3 class="text-blue-600">Step 3: Position Embedding (你在哪？)</h3>
        <p>Transformer 是"位置盲"的。为了让模型知道猫头在猫身的上面，我们需要给每个 Patch 加上一个位置编码向量。</p>

        <h3 class="text-blue-600">Step 4: Transformer Encoder</h3>
        <p>加上了位置编码的序列（外加一个用于分类的 <code>[CLS]</code> token），进入标准的 Transformer 编码器层层处理。</p>

        <ViTArchitecture />
    </div>

    <div class="card">
        <h2>3. ViT 在多模态 AI (VLM) 中的位置</h2>
        <p>VLM（视觉语言模型）的架构通常包括三个部分：<strong>视觉编码器、多模态连接器、语言模型</strong>。ViT 在这里扮演了"眼睛"的角色。</p>

        <div class="grid grid-cols-1 md:grid-cols-2 gap-4">
            <div>
                <p><strong>流程解析：</strong></p>
                <ol class="list-decimal pl-5 space-y-2 text-gray-700">
                    <li>用户输入一张图片和问题。</li>
                    <li>图片进入 <strong>ViT</strong>，被切成 Patch，输出包含丰富语义的图像特征矩阵（例如 <span set:html={"$256 \\times 768$"}></span>）。</li>
                    <li>特征通过<strong>连接器 (Connector)</strong>，对齐维度（例如调整到 LLM 能接受的 4096 维）。</li>
                    <li>对齐后的视觉特征 + 文本问题，一起喂给 <strong>LLM</strong>（如 GPT, Claude, LLaMA）。</li>
                    <li>LLM 生成回答。</li>
                </ol>
            </div>
            <VLMArchitecture />
        </div>
    </div>

    <div class="card">
        <h2>4. 工程视角：输入与输出</h2>
        <div class="overflow-x-auto">
            <table class="min-w-full divide-y divide-gray-200">
                <thead class="bg-gray-50">
                    <tr>
                        <th class="px-6 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">阶段</th>
                        <th class="px-6 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">数据形态</th>
                        <th class="px-6 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">说明</th>
                    </tr>
                </thead>
                <tbody class="bg-white divide-y divide-gray-200 text-sm">
                    <tr>
                        <td class="px-6 py-4 font-medium text-blue-600">Raw Input</td>
                        <td class="px-6 py-4 font-mono text-gray-600"><span set:html={"$H \\times W \\times C$"}></span></td>
                        <td class="px-6 py-4">标准 RGB 图像 (如 224x224x3)</td>
                    </tr>
                    <tr>
                        <td class="px-6 py-4 font-medium text-blue-600">Patch Flatten</td>
                        <td class="px-6 py-4 font-mono text-gray-600"><span set:html={"$N \\times (P^2 \\cdot C)$"}></span></td>
                        <td class="px-6 py-4">如 <span set:html={"$196 \\times 768$"}></span>。每个 Patch 展平成长向量。</td>
                    </tr>
                    <tr>
                        <td class="px-6 py-4 font-medium text-blue-600">Transformer In</td>
                        <td class="px-6 py-4 font-mono text-gray-600"><span set:html={"$(N+1) \\times D$"}></span></td>
                        <td class="px-6 py-4">加上了 [CLS] token 和位置编码。</td>
                    </tr>
                    <tr>
                        <td class="px-6 py-4 font-medium text-purple-600">分类任务输出</td>
                        <td class="px-6 py-4 font-mono text-gray-600"><span set:html={"$1 \\times K$"}></span></td>
                        <td class="px-6 py-4">只取 [CLS] token 接全连接层做分类。</td>
                    </tr>
                    <tr>
                        <td class="px-6 py-4 font-medium text-purple-600">VLM 任务输出</td>
                        <td class="px-6 py-4 font-mono text-gray-600"><span set:html={"$N \\times D$"}></span></td>
                        <td class="px-6 py-4">保留所有 Patch 的特征序列，用于理解图像细节。</td>
                    </tr>
                </tbody>
            </table>
        </div>
    </div>

    <div class="mt-8 text-center text-gray-500">
        <p>ViT 证明了：不需要复杂的卷积设计，纯粹的 Transformer 也能在视觉领域称王。</p>
    </div>
</BaseLayout>
